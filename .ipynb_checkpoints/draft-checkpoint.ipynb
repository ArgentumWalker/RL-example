{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Начало работы с PyCharm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 1. Откройте / создайте проект в PyCharm\n",
    "(Можно пропустить эту часть, если Вы уже писали программы в PyCharm)\n",
    "\n",
    "Зачем нужен проект?  \n",
    "Все, что Вы делаете в PyCharm, выполняется в контексте проекта. Он служит основой для поддержки кодирования, рефакторинга, согласованности стиля кодирования и т.д.\n",
    "\n",
    "У вас есть два варианта начать работу над проектом внутри среды IDE:\n",
    "1. Открыть существующий проект\n",
    "2. Создать проект с нуля\n",
    "\n",
    "Сегодня Вам необходимо создать новый проект. \n",
    "1. Для этого кликните на «Create New Project».\n",
    "2. В следующем окне будет два поля:  \n",
    "    * В первом укажите, где будет располагаться новый проект. Наример, /Users/macbook/PycharmProjects/untitled. \"untitled\" можно заменить на имя проекта, можете назвать свой проект \"MountainCar\".  \n",
    "    * Второе поле должно быть заполненным по умолчанию. Там содержится путь к установленному ранее Python. \n",
    "3. Дальше откроется окно самого редактора.\n",
    "    Теперь вы готовы начать писать программы на Python!\n",
    "    \n",
    "### Шаг 2. Первая программа \"Hello world\"\n",
    "\n",
    "1. Давайте проверим, как все работает. Для этого кликните правой кнопкой на название вашего проекта и в раскрывающемся списке выберите пункт «New > Python file».  \n",
    "    Появится окно, в котором вы можете задать имя файлу. Задайте какое-нибудь имя и нажмите «OK».\n",
    "2. Справа откроется сам файл. Пока он пустой.  \n",
    "    Скопируйте в него следующий код:  \n",
    "        print(\"Hello, World!\")  \n",
    "    Этот код выводит в консоль строку `Hello, World!`.\n",
    "3.  Теперь нужно запустить нашу небольшую (1 строка) программу. Для этого в верхнем меню перейдите в «Run > Run…».  \n",
    "    В появившемся окне щелкните по названию вашего файла. Теперь программа запустится.  \n",
    "    В нижней части редактора должна появиться консоль с результатом выполнения нашей программы: Hello world  \n",
    "    \n",
    "##### Поздравляем! Вы запустили свою программу"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN и MountainCar\n",
    "### Вступление\n",
    "\n",
    "Привет! Сегодня мы вместе реализуем алгоритм DDQN, который является одним из основных методов deep reinforcement learning, показывающий достаточно высокие результаты на большом количестве задач.\n",
    "\n",
    "Сегодня мы научим машину заезжать на горку. Mountain Car - это классическая задача обучения с подкреплением, цель которой состоит в том, чтобы создать алгоритм, который научится подниматься по крутому склону, чтобы достичь цели, отмеченной флагом. Двигатель автомобиля недостаточно силен, чтобы подняться в гору без разгона, поэтому автомобиль должен подняться по левому склону, чтобы набрать достаточный импульс, чтобы взобраться по крутому правому склону и достичь цели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вспомогательные библиотеки\n",
    "Для начала разберемся с тем, что мы будем использовать.  \n",
    "Во-первых, нам понадобится Python. Желательно Python 3.5 или более новой версии.  \n",
    "Во-вторых, нам потребуются следующие библиотеки для Python:\n",
    "* `gym` - Общий интерфейс для многих сред RL. Команда для установки: `pip install gym`\n",
    "* `numpy` - Библиотека для работы с математикой. Команда для установки: `pip install numpy`\n",
    "* `pytorch` - Фреймворк для реализации и обучения нейронных сетей. [Инструкция по установке](https://pytorch.org/get-started/locally/)\n",
    "* `matplotlib` - Потребуется нам для отображения картинок и графиков. Команда для установки: `pip install matplotlib`\n",
    "\n",
    "После установки всего необходимого, нужно импортировать все нужные нам библиотеки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "# PyTorch\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Устройство, на котором будет работать PyTorch.\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gym\n",
    "Сегодня мы рассмотрим задачу MountainCar, ее можно настроить при помощи Gym от компании OpenAI – это одна из самых популярных библиотек для решения задач на обучение с подкреплением.   \n",
    "\n",
    "Давайте посмотрим, как будет отображаться наша среда. Все модели и интерфейс для этой задачи уже сконфигурированы в gym и поименованы под MountainCar. Давайте создадим окружение `env.reset()`. И попросим отрисовать `env.render()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create environment\n",
    "env = gym.make(\"MountainCar-v0\")\n",
    "state = env.reset()\n",
    "# Show window with rendered Car\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MountainCar: описание\n",
    "\n",
    "Теперь попробуем запустить окржужение, и сделать 3 случайных шага.\n",
    "\n",
    "Изначально автомобиль падает в окружение, получая начальное положение и скорость в виде вектора при инициализации окружения `env.reset()`. Это начальное состояние агента.  \n",
    "\n",
    "Затем  агент должен выполнить одно из трех действий: ехать налево, ничего не делать или ехать направо.  \n",
    "В данном примере дейсвие выбирается случайным образом `action = env.action_space.sample()`.  \n",
    "\n",
    "Это действие отправляется в окружение Mountain Car `env.step(action)`, который возвращает новое состояние (положение и скорость), а также награду. \n",
    "\n",
    "Подсчет награды:  \n",
    "За каждый шаг, когда машина не достигает цели, расположенной в вверхнем правом углу, среда возвращает награду -1.\n",
    "\n",
    "##### MountainCar: случайный алгоритм\n",
    "Далее Вы можете посмотреть, чему равны каждый из описанных выше атрибутов окружения: `action, observation, reward, done, info`  на первых трех шагах алгоритма, при условии случайного выбора дейсвия."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0:\n",
      "action: 0\n",
      "observation: [-0.50795221 -0.00112574]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "\n",
      "Step 1:\n",
      "action: 1\n",
      "observation: [-0.50919526 -0.00124305]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "\n",
      "Step 2:\n",
      "action: 0\n",
      "observation: [-0.51154629 -0.00235104]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "\n",
      "Step 3:\n",
      "action: 1\n",
      "observation: [-0.51398771 -0.00244141]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "\n",
      "Step 4:\n",
      "action: 1\n",
      "observation: [-0.51650119 -0.00251349]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "\n",
      "Step 5:\n",
      "action: 2\n",
      "observation: [-0.5180679  -0.00156671]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "\n",
      "Step 6:\n",
      "action: 0\n",
      "observation: [-0.5206761  -0.00260819]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "\n",
      "Step 7:\n",
      "action: 2\n",
      "observation: [-0.52230621 -0.00163011]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "\n",
      "Step 8:\n",
      "action: 0\n",
      "observation: [-0.52494602 -0.00263981]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "\n",
      "Step 9:\n",
      "action: 0\n",
      "observation: [-0.52857572 -0.0036297 ]\n",
      "reward: -1.0\n",
      "done: False\n",
      "info: {}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def play_a_random_game_first():\n",
    "    goal_steps = 10\n",
    "\n",
    "    for step_index in range(goal_steps):\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        \n",
    "        print(\"Step {}:\".format(step_index))\n",
    "        print(\"action: {}\".format(action))\n",
    "        print(\"observation: {}\".format(observation))\n",
    "        print(\"reward: {}\".format(reward))\n",
    "        print(\"done: {}\".format(done))\n",
    "        print(\"info: {}\".format(info))\n",
    "        print()\n",
    "        if done:\n",
    "            break\n",
    "    env.reset()\n",
    "\n",
    "play_a_random_game_first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение нейронных сетей\n",
    "Поскольку DQN представляет собой нейронную сеть, то ее надо обучатьна каких-то данных. \n",
    "\n",
    "Обучение можно производить тремя методами: \n",
    "* стохастический метод (stochastic)   \n",
    "    Метод работает по следующему принципу — ставится один эксперемент, далее считается  Δw, и сразу по ним обновляютсяи соответствующие веса нейронной сети.  \n",
    "    Этот метод является самым точным.\n",
    "* пакетный метод (batch)  \n",
    "    Пакетный метод работает по-другому. Проводиться несколько эксперементов, и далее  суммируются Δw всех весов на текущей итерации. И только потом обновляем все веса используя эту сумму.  \n",
    "    Один из самых важных плюсов такого подхода — это значительная экономия времени на вычисление.  \n",
    "    Однако,точность же в таком случае может сильно пострадать.\n",
    "* мини-пакетный метод (mini-batch)  \n",
    "    Мини-пакетный метод является золотой серединой и пытается совместить в себе плюсы обоих методов. Здесь принцип таков: Δw полученные в ходе эксперементов, в свободном порядке распределяем  по группам. И далее внутри каждой группы вычисляется сумма Δw, и в соответсвие с ней меняются веса нейронной сети.\n",
    "\n",
    "##### Адаптация для обучения с подкреплением\n",
    "Обычно батчи (пакеты) выбираются случайно из набора данных, однако, в нашем случае набора данных нет, как было бы в случае распознования картинок, когда заранее дан размеченный датасет. В данном случае есть только среда и возможность взаимодействовать с ней.  \n",
    "Решение этой проблемы очень простое: давайте создадим буфер ограниченного размера, в который будем складывать replay (атрибуты окружения: `action, observation, reward, done, info`) , полученные в результате взаимодействия со средой.  \n",
    "При этом надо учесть, что случайно сгенерированные данные могут сожержать странные состояния, по которой не хочется обучаться, поэтому удаляем самые старые, если не хватает места. Этот буфер мы будем считать нашим набором данных и брать батчи прямо из него."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory:\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, element):\n",
    "        \"\"\"Сохраняет элемент в циклический буфер\"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = element\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        \"\"\"Возвращает случайную выборку указанного размера\"\"\"\n",
    "        return random.sample(self.memory, batch_size)\n",
    "    \n",
    "    def clear(self):\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "\n",
    "memory = Memory(5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Описание архитектуры нейронной сети\n",
    "Теперь пришло время описать архитектуру самой нейронной сети. Первые три слоя - сверточные, затем идет один линейный слой, которой выделяет признаки и в конце слой, который комбинирует эти признаки в Q-function для каждого действия в данном состоянии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_model():\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(2, 32),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(32, 32),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(32, 3)\n",
    "    )\n",
    "\n",
    "    target_model = copy.deepcopy(model)\n",
    "    \n",
    "    #Инициализация весов нейронной сети\n",
    "    def init_weights(layer):\n",
    "        if type(layer) == nn.Linear:\n",
    "            nn.init.xavier_normal(layer.weight)\n",
    "\n",
    "    model.apply(init_weights)\n",
    "    \n",
    "    #Загружаем модель на устройство, определенное в самом начале (GPU или CPU)\n",
    "    model.train()\n",
    "    target_model.train()\n",
    "    model.to(device)\n",
    "    target_model.to(device)\n",
    "    \n",
    "    #Сразу зададим оптимизатор, с помощью которого будем обновлять веса модели\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.00003)\n",
    "    \n",
    "    return model, target_model, optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также нужно описать функцию, которая будет по батчу считать функцию потерь и запускать обновление весов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.99\n",
    "\n",
    "def fit(batch):\n",
    "        state, action, reward, next_state, done = batch\n",
    "        # Загружаем батч на выбранное ранее устройство\n",
    "        state = torch.tensor(state).to(device).float()\n",
    "        next_state = torch.tensor(next_state).to(device).float()\n",
    "        reward = torch.tensor(reward).to(device).float()\n",
    "        action = torch.tensor(action).to(device)\n",
    "\n",
    "        # Считаем то, какие значения должна выдавать наша сеть\n",
    "        target_q = torch.zeros(reward.size()[0]).float().to(device)\n",
    "        with torch.no_grad():\n",
    "            # Выбираем максимальное из значений Q-function для следующего состояяния\n",
    "            target_q[done] = target_model(next_state).max(1)[0].detach()[done]\n",
    "        target_q = reward + target_q * gamma\n",
    "\n",
    "        #Current approximation\n",
    "        q = model(state).gather(1, action.unsqueeze(1))\n",
    "\n",
    "        loss = F.smooth_l1_loss(q, target_q.unsqueeze(1))\n",
    "\n",
    "        # Очищаем текущие градиенты внутри сети\n",
    "        optimizer.zero_grad()\n",
    "        # Применяем обратное распространение  ошибки\n",
    "        loss.backward()\n",
    "        # Ограничиваем значения градиента. Необходимо, чтобы обновления не были слишком большими\n",
    "        for param in model.parameters():\n",
    "            param.grad.data.clamp_(-1, 1)\n",
    "        # Делаем шаг оптимизации\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также опишем ε-greedy политику, которая совершает случайное действие с вероятностью ε в целях исследования среды."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(state, epsilon):\n",
    "    if random.random() < epsilon:\n",
    "        return random.randint(0, 2)\n",
    "    return model(torch.tensor(state).to(device).float().unsqueeze(0))[0].max(0)[1].view(1, 1).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пришло время, наконец, обучить нашу модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exploit(render=False):\n",
    "    state = env.reset()\n",
    "    r = 0.\n",
    "    done = False\n",
    "    while not done:\n",
    "        # Exploitation происходит без exploration\n",
    "        epsilon = 0.\n",
    "        if render:\n",
    "                env.render()\n",
    "        action = select_action(state, epsilon)\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        r += reward\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ArgentumWalker\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e5f6f72c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random.seed(1)\n",
    "target_update = 1000\n",
    "batch_size = 128\n",
    "def train_base():\n",
    "    reward_by_update = []\n",
    "    max_step = 20001\n",
    "    state = env.reset()\n",
    "    for step in range(1, max_step):\n",
    "        # Exploration Rate decay\n",
    "        epsilon = 1 - 0.9 * step / max_step\n",
    "        action = select_action(state, epsilon)\n",
    "        new_state, reward, done, _ = env.step(action)\n",
    "\n",
    "        if done:\n",
    "            memory.push((state, action, reward, new_state, done))\n",
    "            state = env.reset()\n",
    "            done = False\n",
    "        else:\n",
    "            memory.push((state, action, reward, new_state, done))\n",
    "            state = new_state\n",
    "\n",
    "        if step > batch_size:\n",
    "            fit(list(zip(*memory.sample(batch_size))))\n",
    "\n",
    "        if step % target_update == 0:\n",
    "            target_model = copy.deepcopy(model)\n",
    "            state = env.reset()\n",
    "            r = exploit(False)\n",
    "            reward_by_update.append(r)\n",
    "        \n",
    "    return reward_by_update\n",
    "\n",
    "            \n",
    "model, target_model, optimizer = create_new_model()\n",
    "memory.clear()\n",
    "reward_by_update = train_base()\n",
    "\n",
    "plt.plot(list(range(len(reward_by_update))), reward_by_update)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ой, кажется наш агент так ничему и не научился! Что же пошло не так? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reward Shaping\n",
    "Все дело в том, что сейчас чтобы агент научился въезжать на холм, он должен несколько раз туда заехать случайно, чтобы понять, что это приносит ему большую суммарную награду. Поскольку вознаграждение агента никогда не изменяется до успешного завершения эпизода. Однако заехать на холм просто совершая случайные действия крайне маловероятно, из-за чего автомобиль не научился заезжать на холм.  \n",
    "\n",
    "Одним из способов решения этой проблемы является Reward Shaping - изменение функции награды с учетом нашего знания особенностей задачи для того, чтобы подсказать агенту, как нужно действовать в данной ситуации.\n",
    "\n",
    "В качестве модификации функции  награды используем модуль текущей скорости как аддитивную добавку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ArgentumWalker\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e5f6f9f320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random.seed(1)\n",
    "def train_shaped():\n",
    "    reward_by_update = []\n",
    "    max_step = 20001\n",
    "    state = env.reset()\n",
    "    for step in range(1, max_step):\n",
    "        epsilon = 1 - 0.9 * step / max_step\n",
    "        action = select_action(state, epsilon)\n",
    "        new_state, reward, done, _ = env.step(action)\n",
    "\n",
    "        if done:\n",
    "            memory.push((state, action, reward, state, done))\n",
    "            state = env.reset()\n",
    "            done = False\n",
    "        else:\n",
    "            # Единственное отличие в этой строке. К награде добавили модуль скорости с коэффициентом\n",
    "            memory.push((state, action, reward + 5 * abs(new_state[1]), new_state, done))\n",
    "            state = new_state\n",
    "\n",
    "        if step > batch_size:\n",
    "            fit(list(zip(*memory.sample(batch_size))))\n",
    "\n",
    "        if step % target_update == 0:\n",
    "            target_model = copy.deepcopy(model)\n",
    "            state = env.reset()\n",
    "            r = exploit(False)\n",
    "            reward_by_update.append(r)\n",
    "            \n",
    "    return reward_by_update\n",
    "    \n",
    "model, target_model, optimizer = create_new_model()\n",
    "memory.clear()\n",
    "reward_by_update = train_shaped()\n",
    "\n",
    "plt.plot(list(range(len(reward_by_update))), reward_by_update)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ура! Модель начала обучаться! И автомобиль смог заехать на гору!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
