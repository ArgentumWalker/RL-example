{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN и PacMan\n",
    "### Вступление\n",
    "\n",
    "Привет! Сегодня мы вместе реализуем алгоритм DDQN, который является одним из самых простых методов deep reinforcement learning, однако при этом показывает достаточно высокие результаты на большом количестве задач. Более того, архитектура, приведенная в [статье](https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf) позволяет эффективно решать целый спектр различных задач без адаптации алгоритма к их условиям."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Требования\n",
    "Для начала разберемся с тем, что мы будем использовать. Во-первых, нам понадобится Python 3.5+ и Linux (к сожалению, некоторые библиотеки могут некорректно работать с другими ОС). Во-вторых, нам потребуются следующие библиотеки для Python:\n",
    "* `gym` - Общий интерфейс для многих сред RL. Рекомендуется устанавливать вместе с пакетом игр atari, т.к. это позволит в дальнейшем не исправлять зависимости вручную. Команда для установки: `pip install gym[atari]`\n",
    "* `numpy` - Библиотека для работы с математикой. Команда для установки: `pip install numpy`\n",
    "* `pytorch` - Фреймворк для реализации и обучения нейронных сетей. [Инструкция по установке](https://pytorch.org/get-started/locally/)\n",
    "* `matplotlib` - Потребуется нам для отображения картинок и графиков. Команда для установки: `pip install matplotlib`\n",
    "\n",
    "После установки всего необходимого, нужно импортировать все нужные нам библиотеки в скрипт:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#Определяем, можем ли использовать cuda для вычислений на GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### До создания модели\n",
    "Теперь создадим окружение, на котором будем тестировать алгоритм. В качестве примера будем использовать игру *PacMan*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create environment\n",
    "env = gym.make(\"MsPacman-v0\")\n",
    "frame = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Отобразим фрейм из начала игры\n",
    "plt.imshow(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Естественно, мы не будем использовать исходное изображение в качестве наблюдения. Оно слишком большое и цветное. Мы сделаем его черно-белым и уменьшим до размера 84x84 с помощью масштабирования и обрезания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_grayscale(image):\n",
    "    #Константы взяты из https://en.wikipedia.org/wiki/Grayscale\n",
    "    return 0.2126 * image[:, :, 0] + 0.7152 * image[:, :, 1] + 0.0722 * image[:, :, 2]\n",
    "\n",
    "\n",
    "def preprocesing(image):\n",
    "    grayscale = to_grayscale(image)\n",
    "    #Предполагаем, что изображение имеет размер 160x210\n",
    "    #После такой трансформации изображение будет отмаштабировано, а нижняя часть - обрезана\n",
    "    return [[grayscale[i * 160 // 84, j * 160 // 84]for j in range(84)] for i in range(84)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'frame' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-15d552e7cb01>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreprocesing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"gray\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'frame' is not defined"
     ]
    }
   ],
   "source": [
    "#Посмотрим на результат\n",
    "plt.imshow(preprocesing(frame), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку DQN представляет собой нейронную сеть, то обучаться она будет, как и любая другая нейронная сеть, при помощи батчей. Обычно батчи выбираются случайно из набора данных, однако в нашем случае его нет, а есть только среда и возможность взаимодействовать с ней. Решение этой проблемы очень простое: давайте создадим буфер ограниченного размера, в который будем складывать replay'и, полученные в результате взаимодействия со средой, при этом удаляя самые старые, если не хватает места. Этот буфер мы будем считать нашим набором данных и брать батчи прямо из него."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory:\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, element):\n",
    "        \"\"\"Saves a transition.\"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = element\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "\n",
    "memory = Memory(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Описание модели\n",
    "Теперь пришло время описать архитектуру самой нейронной сети. Первые три слоя - сверточные, затем идет один линейный слой, которой выделяет признаки и в конце слой, который комбинирует эти признаки в Q-function для каждого действия в данном состоянии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(4, 32, 8, 4),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(32, 64, 4, 2),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(64, 64, 3, 1),\n",
    "    nn.ReLU(),\n",
    "    Flatten(),\n",
    "    nn.Linear(3136, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, 5)\n",
    ")\n",
    "\n",
    "target_model = copy.deepcopy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Инициализация весов нейронной сети\n",
    "def init_weights(layer):\n",
    "    if type(layer) == nn.Linear or type(layer) == nn.Conv2d:\n",
    "        nn.init.xavier_normal(layer.weight)\n",
    "\n",
    "\n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Загружаем модель на устройство, определенное в самом начале (GPU или CPU)\n",
    "model.train()\n",
    "target_model.train()\n",
    "model.to(device)\n",
    "target_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сразу зададим оптимизатор, с помощью которого будем обновлять веса модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.RMSprop(model.parameters(), lr=0.00025, alpha=0.95, eps=0.01)\n",
    "gamma = 0.99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Осталось описать функцию, которая будет по батчу считать функцию потерь и запускать обновление весов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(batch):\n",
    "        state, action, reward, next_state, done = batch\n",
    "        state = torch.tensor(state).to(device).float()\n",
    "        next_state = torch.tensor(next_state).to(device).float()\n",
    "        reward = torch.tensor(reward).to(device).float()\n",
    "        action = torch.tensor(action).to(device)\n",
    "\n",
    "        target_q = torch.zeros(reward.size()[0]).float().to(device)\n",
    "        with torch.no_grad():\n",
    "            #Get predicted by target model Q-function\n",
    "            target_q[done] = target_model(next_state).max(1)[0].detach()\n",
    "        #Estimate current Q-function\n",
    "        target_q = reward + target_q * gamma\n",
    "\n",
    "        #Current approximation\n",
    "        q = model(state).gather(1, action.unsqueeze(1))\n",
    "\n",
    "        loss = F.smooth_l1_loss(q, target_q.unsqueeze(1))\n",
    "\n",
    "        #Clear all gradients of network\n",
    "        optimizer.zero_grad()\n",
    "        #Backpropagate loss\n",
    "        loss.backward()\n",
    "        #Clip gradient\n",
    "        for param in model.parameters():\n",
    "            param.grad.data.clamp_(-1, 1)\n",
    "        #Update network parameters\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также опишем $\\Epsilon$-greedy политику, которая совершает случайное действие с вероятностью $\\Epsilon$ в целях исследования среды."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Вероятность совершить случайное действие(exploration probability)\n",
    "epsilon = 1\n",
    "\n",
    "def select_action(state):\n",
    "    if random.random() < epsilon:\n",
    "        return random.randint(0, 4)\n",
    "    return model(torch.tensor(state).to(device).float().unsqueeze(0))[0].max(0)[1].view(1, 1).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пришло время, наконец, обучить нашу модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_four_frames = deque(maxlen=4)\n",
    "\n",
    "for i in range(4):\n",
    "    last_four_frames.append(frame)\n",
    "actual_state = np.swapaxes(np.concatenate(last_four_frames, axis=2), 2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_step = 100001\n",
    "for step in range(1, max_step):\n",
    "    epsilon = 1 - 0.9 * step / max_step\n",
    "    action = select_action(actual_state)\n",
    "    state, reward, done, _ = env.step(action)\n",
    "    last_four_frames.append(np.expand_dims(preprocesing(state), 2))\n",
    "\n",
    "    if done:\n",
    "        #We need to reset environment and frames deque\n",
    "        memory.push((actual_state, action, reward, actual_state, done))\n",
    "        frame = env.reset()\n",
    "        for i in range(4):\n",
    "            last_four_frames.append(np.expand_dims(preprocesing(frame), 2))\n",
    "        done = False\n",
    "        actual_state = np.swapaxes(np.concatenate(last_four_frames, axis=2), 2, 0)\n",
    "    else:\n",
    "        new_state = np.swapaxes(np.concatenate(last_four_frames, axis=2), 2, 0)\n",
    "        memory.push((actual_state, action, reward, new_state, done))\n",
    "        actual_state = new_state\n",
    "\n",
    "    if step > 32:\n",
    "        fit(list(zip(*memory.sample(32))))\n",
    "\n",
    "    if step % 1000 == 0:\n",
    "        target_model = copy.deepcopy(model)\n",
    "        print(\"Progress\", step // 1000, \"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
